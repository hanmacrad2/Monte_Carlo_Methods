{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC: Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import grad\n",
    "import autograd.numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python hamiltonian_mc.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leapfrog(q, p, dVdq, path_len, step_size):\n",
    "    \"\"\"Leapfrog integrator for Hamiltonian Monte Carlo.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q : np.floatX\n",
    "        Initial position\n",
    "    p : np.floatX\n",
    "        Initial momentum\n",
    "    dVdq : callable\n",
    "        Gradient of the velocity\n",
    "    path_len : float\n",
    "        How long to integrate for\n",
    "    step_size : float\n",
    "        How long each integration step should be\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    q, p : np.floatX, np.floatX\n",
    "        New position and momentum\n",
    "    \"\"\"\n",
    "    q, p = np.copy(q), np.copy(p)\n",
    "\n",
    "    p -= step_size * dVdq(q) / 2  # half step\n",
    "    for _ in range(int(path_len / step_size) - 1):\n",
    "        q += step_size * p  # whole step\n",
    "        p -= step_size * dVdq(q)  # whole step\n",
    "    q += step_size * p  # whole step\n",
    "    p -= step_size * dVdq(q) / 2  # half step\n",
    "\n",
    "    # momentum flip at end\n",
    "    return q, -p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamiltonian_monte_carlo(n_samples, negative_log_prob, initial_position, path_len=1, step_size=0.5):\n",
    "    \"\"\"Run Hamiltonian Monte Carlo sampling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        Number of samples to return\n",
    "    negative_log_prob : callable\n",
    "        The negative log probability to sample from\n",
    "    initial_position : np.array\n",
    "        A place to start sampling from.\n",
    "    path_len : float\n",
    "        How long each integration path is. Smaller is faster and more correlated.\n",
    "    step_size : float\n",
    "        How long each integration step is. Smaller is slower and more accurate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Array of length `n_samples`.\n",
    "    \"\"\"\n",
    "    # autograd magic\n",
    "    dVdq = grad(negative_log_prob)\n",
    "\n",
    "    # collect all our samples in a list\n",
    "    samples = [initial_position]\n",
    "\n",
    "    # Keep a single object for momentum resampling\n",
    "    momentum = st.norm(0, 1)\n",
    "\n",
    "    # If initial_position is a 10d vector and n_samples is 100, we want\n",
    "    # 100 x 10 momentum draws. We can do this in one call to momentum.rvs, and\n",
    "    # iterate over rows\n",
    "    size = (n_samples,) + initial_position.shape[:1]\n",
    "    for p0 in momentum.rvs(size=size):\n",
    "        # Integrate over our path to get a new position and momentum\n",
    "        q_new, p_new = leapfrog(\n",
    "            samples[-1],\n",
    "            p0,\n",
    "            dVdq,\n",
    "            path_len=path_len,\n",
    "            step_size=step_size,\n",
    "        )\n",
    "\n",
    "        # Check Metropolis acceptance criterion\n",
    "        start_log_p = negative_log_prob(samples[-1]) - np.sum(momentum.logpdf(p0))\n",
    "        new_log_p = negative_log_prob(q_new) - np.sum(momentum.logpdf(p_new))\n",
    "        if np.log(np.random.rand()) < start_log_p - new_log_p:\n",
    "            samples.append(q_new)\n",
    "        else:\n",
    "            samples.append(np.copy(samples[-1]))\n",
    "\n",
    "    return np.array(samples[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "\n",
    "neg_log_p = neg_log_mvnormal(np.zeros(2), np.eye(2))\n",
    "ss, pp, mm, pl = [], [], [], [1, 2, 4]\n",
    "for path_len in pl:\n",
    "    samples, positions, momentums, accepted = \n",
    "    hamiltonian_monte_carlo(10, neg_log_p, np.random.randn(2), path_len=path_len, step_size=0.01)\n",
    "    ss.append(samples)\n",
    "    pp.append(positions)\n",
    "    mm.append(momentums)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
